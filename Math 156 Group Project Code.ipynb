{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bbafadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data\n",
    "# import download_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06e179e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in data\n",
    "import numpy as np\n",
    "train_X = np.load(\"kmnist-train-imgs.npz\")['arr_0']\n",
    "train_y = np.load(\"kmnist-train-labels.npz\")['arr_0']\n",
    "test_X = np.load(\"kmnist-test-imgs.npz\")['arr_0']\n",
    "test_y = np.load(\"kmnist-test-labels.npz\")['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02bd06f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check shape of data\n",
    "np.shape(train_X), np.shape(train_y), np.shape(test_X), np.shape(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c00516a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1b798c6fbe0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# View 1 of the characters\n",
    "from matplotlib import pyplot as plt\n",
    "img1 = train_X[0]\n",
    "plt.imshow(img1, cmap = plt.get_cmap('gray'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b35bec9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pixel values\n",
    "train_X = train_X / 255.0\n",
    "test_X = test_X / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7963cba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape Datasets\n",
    "train_X = train_X.reshape(train_X.shape[0], 28, 28, 1)\n",
    "test_X = test_X.reshape(test_X.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26cadfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import neural network libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01dc3149",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "train_y = to_categorical(train_y)\n",
    "test_y = to_categorical(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89af9371",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "876c631d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "feb0552f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "47533328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1688/1688 [==============================] - 16s 9ms/step - loss: 0.3562 - accuracy: 0.8919 - val_loss: 0.1829 - val_accuracy: 0.9447\n",
      "Epoch 2/3\n",
      "1688/1688 [==============================] - 15s 9ms/step - loss: 0.1532 - accuracy: 0.9540 - val_loss: 0.1441 - val_accuracy: 0.9575\n",
      "Epoch 3/3\n",
      "1688/1688 [==============================] - 15s 9ms/step - loss: 0.1127 - accuracy: 0.9666 - val_loss: 0.1079 - val_accuracy: 0.9665\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9075000286102295"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape = (28, 28, 1)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    " optimizer='adam',\n",
    " metrics=['accuracy'])\n",
    "model.fit(train_X, train_y, batch_size = 32, epochs = 3, validation_split = 0.1)\n",
    "\n",
    "model.evaluate(test_X, test_y, verbose = 0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b67e1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3375/3375 [==============================] - 70s 21ms/step - loss: 0.2625 - accuracy: 0.9184 - val_loss: 0.1704 - val_accuracy: 0.9468\n",
      "Test set loss: 0.41284793615341187, test set accuracy: 0.8866999745368958\n",
      "3375/3375 [==============================] - 69s 20ms/step - loss: 0.1130 - accuracy: 0.9645 - val_loss: 0.0991 - val_accuracy: 0.9717\n",
      "Test set loss: 0.3188423216342926, test set accuracy: 0.917900025844574\n",
      "3375/3375 [==============================] - 75s 22ms/step - loss: 0.0786 - accuracy: 0.9755 - val_loss: 0.1249 - val_accuracy: 0.9638\n",
      "Test set loss: 0.3354545533657074, test set accuracy: 0.9161999821662903\n",
      "3375/3375 [==============================] - 75s 22ms/step - loss: 0.0556 - accuracy: 0.9825 - val_loss: 0.1071 - val_accuracy: 0.9707\n",
      "Test set loss: 0.2871098816394806, test set accuracy: 0.9327999949455261\n",
      "3375/3375 [==============================] - 75s 22ms/step - loss: 0.0440 - accuracy: 0.9862 - val_loss: 0.0891 - val_accuracy: 0.9765\n",
      "Test set loss: 0.2563764750957489, test set accuracy: 0.944100022315979\n",
      "3375/3375 [==============================] - 75s 22ms/step - loss: 0.0356 - accuracy: 0.9890 - val_loss: 0.0851 - val_accuracy: 0.9780\n",
      "Test set loss: 0.26593199372291565, test set accuracy: 0.9473000168800354\n",
      "3375/3375 [==============================] - 73s 22ms/step - loss: 0.0288 - accuracy: 0.9910 - val_loss: 0.0976 - val_accuracy: 0.9783\n",
      "Test set loss: 0.2832331955432892, test set accuracy: 0.9440000057220459\n",
      "3375/3375 [==============================] - 75s 22ms/step - loss: 0.0274 - accuracy: 0.9918 - val_loss: 0.0927 - val_accuracy: 0.9810\n",
      "Test set loss: 0.2823942005634308, test set accuracy: 0.946399986743927\n",
      "3375/3375 [==============================] - 77s 23ms/step - loss: 0.0207 - accuracy: 0.9939 - val_loss: 0.1205 - val_accuracy: 0.9758\n",
      "Test set loss: 0.3296242356300354, test set accuracy: 0.9409999847412109\n",
      "3375/3375 [==============================] - 76s 22ms/step - loss: 0.0224 - accuracy: 0.9932 - val_loss: 0.1043 - val_accuracy: 0.9800\n",
      "Test set loss: 0.3340023159980774, test set accuracy: 0.9470000267028809\n",
      "3375/3375 [==============================] - 77s 23ms/step - loss: 0.0181 - accuracy: 0.9944 - val_loss: 0.1127 - val_accuracy: 0.9797\n",
      "Test set loss: 0.34652793407440186, test set accuracy: 0.9452000260353088\n",
      "3375/3375 [==============================] - 76s 22ms/step - loss: 0.0201 - accuracy: 0.9941 - val_loss: 0.1122 - val_accuracy: 0.9817\n",
      "Test set loss: 0.3582603633403778, test set accuracy: 0.9434000253677368\n",
      "3375/3375 [==============================] - 76s 22ms/step - loss: 0.0188 - accuracy: 0.9944 - val_loss: 0.1157 - val_accuracy: 0.9805\n",
      "Test set loss: 0.3834739923477173, test set accuracy: 0.941100001335144\n",
      "3375/3375 [==============================] - 76s 23ms/step - loss: 0.0146 - accuracy: 0.9961 - val_loss: 0.1143 - val_accuracy: 0.9802\n",
      "Test set loss: 0.32402005791664124, test set accuracy: 0.9513000249862671\n",
      "3375/3375 [==============================] - 77s 23ms/step - loss: 0.0154 - accuracy: 0.9959 - val_loss: 0.1355 - val_accuracy: 0.9803\n",
      "Test set loss: 0.33941248059272766, test set accuracy: 0.953000009059906\n",
      "3375/3375 [==============================] - 78s 23ms/step - loss: 0.0149 - accuracy: 0.9960 - val_loss: 0.1350 - val_accuracy: 0.9803\n",
      "Test set loss: 0.4003673493862152, test set accuracy: 0.9473000168800354\n",
      "3375/3375 [==============================] - 76s 22ms/step - loss: 0.0144 - accuracy: 0.9965 - val_loss: 0.1403 - val_accuracy: 0.9780\n",
      "Test set loss: 0.3926265239715576, test set accuracy: 0.9451000094413757\n",
      "3375/3375 [==============================] - 79s 23ms/step - loss: 0.0141 - accuracy: 0.9963 - val_loss: 0.1297 - val_accuracy: 0.9815\n",
      "Test set loss: 0.34894701838493347, test set accuracy: 0.9527999758720398\n",
      "3375/3375 [==============================] - 77s 23ms/step - loss: 0.0139 - accuracy: 0.9964 - val_loss: 0.1261 - val_accuracy: 0.9788\n",
      "Test set loss: 0.36712101101875305, test set accuracy: 0.9492999911308289\n",
      "3375/3375 [==============================] - 78s 23ms/step - loss: 0.0127 - accuracy: 0.9966 - val_loss: 0.1420 - val_accuracy: 0.9822\n",
      "Test set loss: 0.37820619344711304, test set accuracy: 0.954800009727478\n",
      "3375/3375 [==============================] - 79s 23ms/step - loss: 0.0141 - accuracy: 0.9962 - val_loss: 0.1654 - val_accuracy: 0.9797\n",
      "Test set loss: 0.46764886379241943, test set accuracy: 0.9470000267028809\n",
      "3375/3375 [==============================] - 77s 23ms/step - loss: 0.0112 - accuracy: 0.9969 - val_loss: 0.1907 - val_accuracy: 0.9767\n",
      "Test set loss: 0.5392537117004395, test set accuracy: 0.9444000124931335\n",
      "3375/3375 [==============================] - 78s 23ms/step - loss: 0.0148 - accuracy: 0.9964 - val_loss: 0.1424 - val_accuracy: 0.9807\n",
      "Test set loss: 0.48090770840644836, test set accuracy: 0.9456999897956848\n",
      "3375/3375 [==============================] - 78s 23ms/step - loss: 0.0107 - accuracy: 0.9972 - val_loss: 0.1519 - val_accuracy: 0.9837\n",
      "Test set loss: 0.46856489777565, test set accuracy: 0.9495999813079834\n",
      "3375/3375 [==============================] - 77s 23ms/step - loss: 0.0115 - accuracy: 0.9972 - val_loss: 0.1737 - val_accuracy: 0.9820\n",
      "Test set loss: 0.5138706564903259, test set accuracy: 0.9485999941825867\n",
      " 297/3375 [=>............................] - ETA: 1:10 - loss: 0.0201 - accuracy: 0.9971"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\N\\Documents\\homework\\math 156\\project\\Math 156 Group Project Code.ipynb Cell 17'\u001b[0m in \u001b[0;36m<cell line: 41>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/N/Documents/homework/math%20156/project/Math%20156%20Group%20Project%20Code.ipynb#ch0000017?line=39'>40</a>\u001b[0m history \u001b[39m=\u001b[39m []\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/N/Documents/homework/math%20156/project/Math%20156%20Group%20Project%20Code.ipynb#ch0000017?line=40'>41</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(EPOCHS):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/N/Documents/homework/math%20156/project/Math%20156%20Group%20Project%20Code.ipynb#ch0000017?line=41'>42</a>\u001b[0m     history\u001b[39m.\u001b[39mappend(model\u001b[39m.\u001b[39;49mfit(train_X, train_y, batch_size \u001b[39m=\u001b[39;49m BATCH_SIZE, epochs \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m, validation_split \u001b[39m=\u001b[39;49m VAL_SPLIT))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/N/Documents/homework/math%20156/project/Math%20156%20Group%20Project%20Code.ipynb#ch0000017?line=42'>43</a>\u001b[0m     test_out \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(test_X, test_y, verbose \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/N/Documents/homework/math%20156/project/Math%20156%20Group%20Project%20Code.ipynb#ch0000017?line=43'>44</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTest set loss: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, test set accuracy: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(test_out[\u001b[39m0\u001b[39m], test_out[\u001b[39m1\u001b[39m]))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/utils/traceback_utils.py?line=61'>62</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/utils/traceback_utils.py?line=62'>63</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/utils/traceback_utils.py?line=63'>64</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/engine/training.py?line=1376'>1377</a>\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/engine/training.py?line=1377'>1378</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/engine/training.py?line=1378'>1379</a>\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/engine/training.py?line=1379'>1380</a>\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/engine/training.py?line=1380'>1381</a>\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/engine/training.py?line=1381'>1382</a>\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/engine/training.py?line=1382'>1383</a>\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/engine/training.py?line=1383'>1384</a>\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/engine/training.py?line=1384'>1385</a>\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/keras/engine/training.py?line=1385'>1386</a>\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=147'>148</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=148'>149</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=149'>150</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=150'>151</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=151'>152</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/eager/def_function.py?line=911'>912</a>\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/eager/def_function.py?line=913'>914</a>\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/eager/def_function.py?line=914'>915</a>\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/eager/def_function.py?line=916'>917</a>\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/eager/def_function.py?line=917'>918</a>\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/eager/def_function.py?line=943'>944</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/eager/def_function.py?line=944'>945</a>\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/eager/def_function.py?line=945'>946</a>\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/eager/def_function.py?line=946'>947</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/eager/def_function.py?line=947'>948</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/eager/def_function.py?line=948'>949</a>\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/eager/def_function.py?line=949'>950</a>\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/eager/def_function.py?line=950'>951</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=2952'>2953</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=2953'>2954</a>\u001b[0m   (graph_function,\n\u001b[0;32m   <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=2954'>2955</a>\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=2955'>2956</a>\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=2956'>2957</a>\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=1848'>1849</a>\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=1849'>1850</a>\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=1850'>1851</a>\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=1851'>1852</a>\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=1852'>1853</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=1853'>1854</a>\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=1854'>1855</a>\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=1855'>1856</a>\u001b[0m     args,\n\u001b[0;32m   <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=1856'>1857</a>\u001b[0m     possible_gradient_type,\n\u001b[0;32m   <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=1857'>1858</a>\u001b[0m     executing_eagerly)\n\u001b[0;32m   <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=1858'>1859</a>\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=496'>497</a>\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=497'>498</a>\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=498'>499</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=499'>500</a>\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=500'>501</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=501'>502</a>\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=502'>503</a>\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=503'>504</a>\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=504'>505</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=505'>506</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=506'>507</a>\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=507'>508</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=510'>511</a>\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/eager/function.py?line=511'>512</a>\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/eager/execute.py?line=51'>52</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/eager/execute.py?line=52'>53</a>\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/eager/execute.py?line=53'>54</a>\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/eager/execute.py?line=54'>55</a>\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/eager/execute.py?line=55'>56</a>\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     <a href='file:///c%3A/Users/N/AppData/Local/Programs/Python/Python310/lib/site-packages/tensorflow/python/eager/execute.py?line=56'>57</a>\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# M6-2 model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), input_shape = (28, 28, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 50\n",
    "VAL_SPLIT = 0.1\n",
    "\n",
    "# opt = SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "history = []\n",
    "for i in range(EPOCHS):\n",
    "    history.append(model.fit(train_X, train_y, batch_size = BATCH_SIZE, epochs = 1, validation_split = VAL_SPLIT))\n",
    "    test_out = model.evaluate(test_X, test_y, verbose = 0)\n",
    "    print(\"Test set loss: {}, test set accuracy: {}\".format(test_out[0], test_out[1]))\n",
    "\n",
    "\n",
    "\n",
    "# Accuracy on test set\n",
    "# model.evaluate(test_X, test_y, verbose = 0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65785c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.26608556509017944, 0.11495079845190048, 0.07657629251480103, 0.05488773062825203, 0.04548388347029686, 0.03608114644885063, 0.02741876058280468, 0.026133619248867035, 0.024337681010365486, 0.021681630983948708], 'accuracy': [0.915314793586731, 0.9638518691062927, 0.9756666421890259, 0.983129620552063, 0.9858888983726501, 0.988703727722168, 0.9913148283958435, 0.9918518662452698, 0.9927592873573303, 0.993759274482727], 'val_loss': [0.1634930968284607, 0.2114003300666809, 0.10772743076086044, 0.11796694993972778, 0.08761326223611832, 0.09510474652051926, 0.13622955977916718, 0.09605921059846878, 0.09540624916553497, 0.0995713621377945], 'val_accuracy': [0.9503333568572998, 0.9401666522026062, 0.9714999794960022, 0.9678333401679993, 0.9791666865348816, 0.9786666631698608, 0.9726666808128357, 0.981166660785675, 0.9816666841506958, 0.9808333516120911]}\n"
     ]
    }
   ],
   "source": [
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ee3de9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3375/3375 [==============================] - 73s 21ms/step - loss: 0.5817 - accuracy: 0.9061 - val_loss: 0.5669 - val_accuracy: 0.9177\n",
      "Epoch 2/10\n",
      "3375/3375 [==============================] - 76s 22ms/step - loss: 0.4479 - accuracy: 0.9444 - val_loss: 0.4946 - val_accuracy: 0.9232\n",
      "Epoch 3/10\n",
      "3375/3375 [==============================] - 77s 23ms/step - loss: 0.3887 - accuracy: 0.9535 - val_loss: 0.4208 - val_accuracy: 0.9480\n",
      "Epoch 4/10\n",
      "3375/3375 [==============================] - 74s 22ms/step - loss: 0.3372 - accuracy: 0.9605 - val_loss: 0.3489 - val_accuracy: 0.9552\n",
      "Epoch 5/10\n",
      "3375/3375 [==============================] - 75s 22ms/step - loss: 0.3071 - accuracy: 0.9642 - val_loss: 0.3676 - val_accuracy: 0.9505\n",
      "Epoch 6/10\n",
      "3375/3375 [==============================] - 73s 22ms/step - loss: 0.2839 - accuracy: 0.9668 - val_loss: 0.3225 - val_accuracy: 0.9568\n",
      "Epoch 7/10\n",
      "3375/3375 [==============================] - 74s 22ms/step - loss: 0.2626 - accuracy: 0.9683 - val_loss: 0.2721 - val_accuracy: 0.9663\n",
      "Epoch 8/10\n",
      "3375/3375 [==============================] - 76s 23ms/step - loss: 0.2521 - accuracy: 0.9698 - val_loss: 0.2967 - val_accuracy: 0.9577\n",
      "Epoch 9/10\n",
      "3375/3375 [==============================] - 76s 23ms/step - loss: 0.2383 - accuracy: 0.9711 - val_loss: 0.2774 - val_accuracy: 0.9602\n",
      "Epoch 10/10\n",
      "3375/3375 [==============================] - 76s 23ms/step - loss: 0.2248 - accuracy: 0.9726 - val_loss: 0.2662 - val_accuracy: 0.9612\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.920799970626831"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regularizer in conv layers\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), input_shape = (28, 28, 1), kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "VAL_SPLIT = 0.1\n",
    "\n",
    "# opt = SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "history2 = model.fit(train_X, train_y, batch_size = BATCH_SIZE, epochs = EPOCHS, validation_split = VAL_SPLIT)\n",
    "\n",
    "# Accuracy on test set\n",
    "model.evaluate(test_X, test_y, verbose = 0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ee3de9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_28 (Conv2D)          (None, 26, 26, 64)        640       \n",
      "                                                                 \n",
      " batch_normalization_25 (Bat  (None, 26, 26, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_33 (Activation)  (None, 26, 26, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_24 (MaxPoolin  (None, 13, 13, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 11, 11, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_26 (Bat  (None, 11, 11, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_34 (Activation)  (None, 11, 11, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_25 (MaxPoolin  (None, 5, 5, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 3, 3, 512)         590336    \n",
      "                                                                 \n",
      " batch_normalization_27 (Bat  (None, 3, 3, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_35 (Activation)  (None, 3, 3, 512)         0         \n",
      "                                                                 \n",
      " max_pooling2d_26 (MaxPoolin  (None, 1, 1, 512)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 4096)              2101248   \n",
      "                                                                 \n",
      " activation_36 (Activation)  (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                40970     \n",
      "                                                                 \n",
      " activation_37 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,809,866\n",
      "Trainable params: 2,808,458\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# regularizer in conv layers\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), input_shape = (28, 28, 1), kernel_regularizer=regularizers.l2(0.0001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(0.0001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), kernel_regularizer=regularizers.l2(0.0001)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "38708baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "3375/3375 [==============================] - 367s 109ms/step - loss: 0.2313 - accuracy: 0.9305 - val_loss: 0.0773 - val_accuracy: 0.9747\n",
      "Test set loss: 0.2012374848127365, test set accuracy: 0.944100022315979\n",
      "Epoch 2\n",
      "3375/3375 [==============================] - 364s 108ms/step - loss: 0.0873 - accuracy: 0.9739 - val_loss: 0.0578 - val_accuracy: 0.9827\n",
      "Test set loss: 0.16544103622436523, test set accuracy: 0.9574000239372253\n",
      "Epoch 3\n",
      "3375/3375 [==============================] - 367s 109ms/step - loss: 0.0624 - accuracy: 0.9816 - val_loss: 0.0591 - val_accuracy: 0.9833\n",
      "Test set loss: 0.16524016857147217, test set accuracy: 0.954800009727478\n",
      "Epoch 4\n",
      "3375/3375 [==============================] - 360s 107ms/step - loss: 0.0494 - accuracy: 0.9860 - val_loss: 0.0410 - val_accuracy: 0.9903\n",
      "Test set loss: 0.1597684621810913, test set accuracy: 0.9614999890327454\n",
      "Epoch 5\n",
      "3375/3375 [==============================] - 374s 111ms/step - loss: 0.0426 - accuracy: 0.9878 - val_loss: 0.0508 - val_accuracy: 0.9865\n",
      "Test set loss: 0.18018360435962677, test set accuracy: 0.9606999754905701\n",
      "Epoch 6\n",
      "3375/3375 [==============================] - 364s 108ms/step - loss: 0.0330 - accuracy: 0.9904 - val_loss: 0.0439 - val_accuracy: 0.9903\n",
      "Test set loss: 0.15082041919231415, test set accuracy: 0.9696999788284302\n",
      "Epoch 7\n",
      "3375/3375 [==============================] - 362s 107ms/step - loss: 0.0318 - accuracy: 0.9914 - val_loss: 0.0517 - val_accuracy: 0.9890\n",
      "Test set loss: 0.161439448595047, test set accuracy: 0.9703999757766724\n",
      "Epoch 8\n",
      "3375/3375 [==============================] - 352s 104ms/step - loss: 0.0277 - accuracy: 0.9925 - val_loss: 0.0567 - val_accuracy: 0.9903\n",
      "Test set loss: 0.1688179224729538, test set accuracy: 0.9703999757766724\n",
      "Epoch 9\n",
      "3375/3375 [==============================] - 360s 107ms/step - loss: 0.0215 - accuracy: 0.9941 - val_loss: 0.0591 - val_accuracy: 0.9875\n",
      "Test set loss: 0.18977570533752441, test set accuracy: 0.9678999781608582\n",
      "Epoch 10\n",
      "3375/3375 [==============================] - 372s 110ms/step - loss: 0.0252 - accuracy: 0.9934 - val_loss: 0.0495 - val_accuracy: 0.9910\n",
      "Test set loss: 0.1484360247850418, test set accuracy: 0.9746000170707703\n"
     ]
    }
   ],
   "source": [
    "# regularizer in conv layers\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "lmbd = 0\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), input_shape = (28, 28, 1), kernel_regularizer=regularizers.l2(lmbd)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(lmbd)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(192, (3, 3), kernel_regularizer=regularizers.l2(lmbd)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(lmbd)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), kernel_regularizer=regularizers.l2(lmbd)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "VAL_SPLIT = 0.1\n",
    "\n",
    "# opt = SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "history3 = []\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    print(\"Epoch \" + str(i + 1))\n",
    "    history3.append(model.fit(train_X, train_y, batch_size = BATCH_SIZE, epochs = 1, validation_split = VAL_SPLIT))\n",
    "    test_out = model.evaluate(test_X, test_y, verbose = 0)\n",
    "    print(\"Test set loss: {}, test set accuracy: {}\".format(test_out[0], test_out[1]))\n",
    "\n",
    "# Accuracy on test set\n",
    "# model.evaluate(test_X, test_y, verbose = 0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "960580e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_75 (Conv2D)          (None, 26, 26, 64)        640       \n",
      "                                                                 \n",
      " batch_normalization_75 (Bat  (None, 26, 26, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_111 (Activation)  (None, 26, 26, 64)       0         \n",
      "                                                                 \n",
      " conv2d_76 (Conv2D)          (None, 24, 24, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_76 (Bat  (None, 24, 24, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_112 (Activation)  (None, 24, 24, 128)      0         \n",
      "                                                                 \n",
      " max_pooling2d_51 (MaxPoolin  (None, 12, 12, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_77 (Conv2D)          (None, 10, 10, 192)       221376    \n",
      "                                                                 \n",
      " batch_normalization_77 (Bat  (None, 10, 10, 192)      768       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_113 (Activation)  (None, 10, 10, 192)      0         \n",
      "                                                                 \n",
      " conv2d_78 (Conv2D)          (None, 8, 8, 256)         442624    \n",
      "                                                                 \n",
      " batch_normalization_78 (Bat  (None, 8, 8, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_114 (Activation)  (None, 8, 8, 256)        0         \n",
      "                                                                 \n",
      " max_pooling2d_52 (MaxPoolin  (None, 4, 4, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_79 (Conv2D)          (None, 2, 2, 512)         1180160   \n",
      "                                                                 \n",
      " batch_normalization_79 (Bat  (None, 2, 2, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_115 (Activation)  (None, 2, 2, 512)        0         \n",
      "                                                                 \n",
      " max_pooling2d_53 (MaxPoolin  (None, 1, 1, 512)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_17 (Flatten)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 4096)              2101248   \n",
      "                                                                 \n",
      " activation_116 (Activation)  (None, 4096)             0         \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 10)                40970     \n",
      "                                                                 \n",
      " activation_117 (Activation)  (None, 10)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,065,482\n",
      "Trainable params: 4,063,178\n",
      "Non-trainable params: 2,304\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# regularizer in conv layers\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "lmbd = 0\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), input_shape = (28, 28, 1), kernel_regularizer=regularizers.l2(lmbd)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(lmbd)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(192, (3, 3), kernel_regularizer=regularizers.l2(lmbd)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(lmbd)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), kernel_regularizer=regularizers.l2(lmbd)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc23325",
   "metadata": {},
   "source": [
    "l2 regularizer, lambda = 10^-6. this exhibits the highest test accuracy after 10 epochs, though not by much.\n",
    "\n",
    "this is the current best code\n",
    "2C -> M -> 2C -> M -> C -> M -> output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "960580e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "3375/3375 [==============================] - 346s 102ms/step - loss: 0.2344 - accuracy: 0.9314 - val_loss: 0.0920 - val_accuracy: 0.9740\n",
      "Test set loss: 0.28041934967041016, test set accuracy: 0.9218999743461609\n",
      "epoch 2\n",
      "3375/3375 [==============================] - 352s 104ms/step - loss: 0.0932 - accuracy: 0.9738 - val_loss: 0.0647 - val_accuracy: 0.9840\n",
      "Test set loss: 0.184462770819664, test set accuracy: 0.9496999979019165\n",
      "epoch 3\n",
      "3375/3375 [==============================] - 350s 104ms/step - loss: 0.0710 - accuracy: 0.9817 - val_loss: 0.0910 - val_accuracy: 0.9792\n",
      "Test set loss: 0.23415109515190125, test set accuracy: 0.9473000168800354\n",
      "epoch 4\n",
      "3375/3375 [==============================] - 360s 107ms/step - loss: 0.0642 - accuracy: 0.9856 - val_loss: 0.0687 - val_accuracy: 0.9853\n",
      "Test set loss: 0.1846080720424652, test set accuracy: 0.9599999785423279\n",
      "epoch 5\n",
      "3375/3375 [==============================] - 347s 103ms/step - loss: 0.0609 - accuracy: 0.9881 - val_loss: 0.0752 - val_accuracy: 0.9882\n",
      "Test set loss: 0.1616337150335312, test set accuracy: 0.9695000052452087\n",
      "epoch 6\n",
      "3375/3375 [==============================] - 351s 104ms/step - loss: 0.0621 - accuracy: 0.9894 - val_loss: 0.0709 - val_accuracy: 0.9867\n",
      "Test set loss: 0.1701846718788147, test set accuracy: 0.965399980545044\n",
      "epoch 7\n",
      "3375/3375 [==============================] - 346s 103ms/step - loss: 0.0578 - accuracy: 0.9913 - val_loss: 0.0719 - val_accuracy: 0.9880\n",
      "Test set loss: 0.1910136342048645, test set accuracy: 0.9682000279426575\n",
      "epoch 8\n",
      "3375/3375 [==============================] - 350s 104ms/step - loss: 0.0611 - accuracy: 0.9918 - val_loss: 0.0846 - val_accuracy: 0.9877\n",
      "Test set loss: 0.18990886211395264, test set accuracy: 0.9696000218391418\n",
      "epoch 9\n",
      "3375/3375 [==============================] - 352s 104ms/step - loss: 0.0577 - accuracy: 0.9931 - val_loss: 0.0911 - val_accuracy: 0.9883\n",
      "Test set loss: 0.1796686202287674, test set accuracy: 0.9711999893188477\n",
      "epoch 10\n",
      "3375/3375 [==============================] - 347s 103ms/step - loss: 0.0618 - accuracy: 0.9928 - val_loss: 0.0899 - val_accuracy: 0.9880\n",
      "Test set loss: 0.14370207488536835, test set accuracy: 0.9758999943733215\n"
     ]
    }
   ],
   "source": [
    "# regularizer in conv layers\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "lmbd = 0.000001\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), input_shape = (28, 28, 1), kernel_regularizer=regularizers.l2(lmbd)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(lmbd)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(192, (3, 3), kernel_regularizer=regularizers.l2(lmbd)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(lmbd)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), kernel_regularizer=regularizers.l2(lmbd)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "VAL_SPLIT = 0.1\n",
    "\n",
    "# opt = SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "history4 = []\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    print(\"epoch \" + str(i + 1))\n",
    "\n",
    "    history4.append( model.fit(train_X, train_y, batch_size = BATCH_SIZE, epochs = 1, validation_split = VAL_SPLIT))\n",
    "    test_out = model.evaluate(test_X, test_y, verbose = 0)\n",
    "    print(\"Test set loss: {}, test set accuracy: {}\".format(test_out[0], test_out[1]))\n",
    "\n",
    "# Accuracy on test set\n",
    "# model.evaluate(test_X, test_y, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "960580e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "3375/3375 [==============================] - 532s 157ms/step - loss: 0.2721 - accuracy: 0.9225 - val_loss: 0.1691 - val_accuracy: 0.9582\n",
      "Test set loss: 0.3780135214328766, test set accuracy: 0.9061999917030334\n",
      "epoch 2\n",
      "3375/3375 [==============================] - 539s 160ms/step - loss: 0.1170 - accuracy: 0.9696 - val_loss: 0.1063 - val_accuracy: 0.9737\n",
      "Test set loss: 0.26877090334892273, test set accuracy: 0.9272000193595886\n",
      "epoch 3\n",
      "3375/3375 [==============================] - 544s 161ms/step - loss: 0.0882 - accuracy: 0.9786 - val_loss: 0.0917 - val_accuracy: 0.9805\n",
      "Test set loss: 0.23080001771450043, test set accuracy: 0.9508000016212463\n",
      "epoch 4\n",
      "3375/3375 [==============================] - 547s 162ms/step - loss: 0.0783 - accuracy: 0.9825 - val_loss: 0.1043 - val_accuracy: 0.9780\n",
      "Test set loss: 0.22811582684516907, test set accuracy: 0.9480000138282776\n",
      "epoch 5\n",
      "3375/3375 [==============================] - 561s 166ms/step - loss: 0.0675 - accuracy: 0.9867 - val_loss: 0.1096 - val_accuracy: 0.9795\n",
      "Test set loss: 0.2765550911426544, test set accuracy: 0.946399986743927\n",
      "epoch 6\n",
      "3375/3375 [==============================] - 553s 164ms/step - loss: 0.0649 - accuracy: 0.9886 - val_loss: 0.0869 - val_accuracy: 0.9857\n",
      "Test set loss: 0.20451082289218903, test set accuracy: 0.9599000215530396\n",
      "epoch 7\n",
      "3375/3375 [==============================] - 560s 166ms/step - loss: 0.0663 - accuracy: 0.9904 - val_loss: 0.0676 - val_accuracy: 0.9905\n",
      "Test set loss: 0.16796450316905975, test set accuracy: 0.9692000150680542\n",
      "epoch 8\n",
      "3375/3375 [==============================] - 558s 165ms/step - loss: 0.0588 - accuracy: 0.9921 - val_loss: 0.0841 - val_accuracy: 0.9887\n",
      "Test set loss: 0.2057766169309616, test set accuracy: 0.9634000062942505\n",
      "epoch 9\n",
      "3375/3375 [==============================] - 560s 166ms/step - loss: 0.0637 - accuracy: 0.9916 - val_loss: 0.0970 - val_accuracy: 0.9885\n",
      "Test set loss: 0.20441609621047974, test set accuracy: 0.968999981880188\n",
      "epoch 10\n",
      "3375/3375 [==============================] - 543s 161ms/step - loss: 0.0622 - accuracy: 0.9924 - val_loss: 0.0827 - val_accuracy: 0.9897\n",
      "Test set loss: 0.16854669153690338, test set accuracy: 0.9751999974250793\n"
     ]
    }
   ],
   "source": [
    "# regularizer in conv layers\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "lmbd = 0.000001\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), input_shape = (28, 28, 1), kernel_regularizer=regularizers.l2(lmbd)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(lmbd)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(192, (3, 3), kernel_regularizer=regularizers.l2(lmbd)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(lmbd)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), kernel_regularizer=regularizers.l2(lmbd)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(4096))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "VAL_SPLIT = 0.1\n",
    "\n",
    "# opt = SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "history10 = []\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    print(\"epoch \" + str(i + 1))\n",
    "\n",
    "    history10.append( model.fit(train_X, train_y, batch_size = BATCH_SIZE, epochs = 1, validation_split = VAL_SPLIT))\n",
    "    test_out = model.evaluate(test_X, test_y, verbose = 0)\n",
    "    print(\"Test set loss: {}, test set accuracy: {}\".format(test_out[0], test_out[1]))\n",
    "\n",
    "# Accuracy on test set\n",
    "# model.evaluate(test_X, test_y, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d004d33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.23435842990875244], 'accuracy': [0.9313518404960632], 'val_loss': [0.09200888127088547], 'val_accuracy': [0.9739999771118164]}\n",
      "{'loss': [0.0932149812579155], 'accuracy': [0.9737963080406189], 'val_loss': [0.06474307924509048], 'val_accuracy': [0.984000027179718]}\n",
      "{'loss': [0.07098165154457092], 'accuracy': [0.9817222356796265], 'val_loss': [0.09099278599023819], 'val_accuracy': [0.9791666865348816]}\n",
      "{'loss': [0.06416907906532288], 'accuracy': [0.9856296181678772], 'val_loss': [0.06869830936193466], 'val_accuracy': [0.9853333234786987]}\n",
      "{'loss': [0.06094818189740181], 'accuracy': [0.988111138343811], 'val_loss': [0.07521344721317291], 'val_accuracy': [0.9881666898727417]}\n",
      "{'loss': [0.062147315591573715], 'accuracy': [0.9893703460693359], 'val_loss': [0.07090605795383453], 'val_accuracy': [0.9866666793823242]}\n",
      "{'loss': [0.05776704475283623], 'accuracy': [0.9913148283958435], 'val_loss': [0.07186000794172287], 'val_accuracy': [0.9879999756813049]}\n",
      "{'loss': [0.061079028993844986], 'accuracy': [0.9917592406272888], 'val_loss': [0.08460649847984314], 'val_accuracy': [0.987666666507721]}\n",
      "{'loss': [0.057730644941329956], 'accuracy': [0.9931296110153198], 'val_loss': [0.09105227887630463], 'val_accuracy': [0.9883333444595337]}\n",
      "{'loss': [0.06182820349931717], 'accuracy': [0.9928333163261414], 'val_loss': [0.08994599431753159], 'val_accuracy': [0.9879999756813049]}\n"
     ]
    }
   ],
   "source": [
    "for i in range(EPOCHS):\n",
    "    print(history4[i].history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e83aa2",
   "metadata": {},
   "source": [
    "l2 regularizer, lambda = 10^-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "960580e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "3375/3375 [==============================] - 347s 103ms/step - loss: 0.2568 - accuracy: 0.9295 - val_loss: 0.1258 - val_accuracy: 0.9732\n",
      "Test set loss: 0.28680360317230225, test set accuracy: 0.9251999855041504\n",
      "epoch 2\n",
      "3375/3375 [==============================] - 345s 102ms/step - loss: 0.1376 - accuracy: 0.9729 - val_loss: 0.1615 - val_accuracy: 0.9728\n",
      "Test set loss: 0.3441077470779419, test set accuracy: 0.9315000176429749\n",
      "epoch 3\n",
      "3375/3375 [==============================] - 342s 101ms/step - loss: 0.1380 - accuracy: 0.9796 - val_loss: 0.1343 - val_accuracy: 0.9838\n",
      "Test set loss: 0.2616465091705322, test set accuracy: 0.9546999931335449\n",
      "epoch 4\n",
      "3375/3375 [==============================] - 342s 101ms/step - loss: 0.1412 - accuracy: 0.9831 - val_loss: 0.1473 - val_accuracy: 0.9840\n",
      "Test set loss: 0.2679396867752075, test set accuracy: 0.9627000093460083\n",
      "epoch 5\n",
      "3375/3375 [==============================] - 343s 102ms/step - loss: 0.1414 - accuracy: 0.9854 - val_loss: 0.1355 - val_accuracy: 0.9893\n",
      "Test set loss: 0.24159695208072662, test set accuracy: 0.9677000045776367\n",
      "epoch 6\n",
      "3375/3375 [==============================] - 342s 101ms/step - loss: 0.1371 - accuracy: 0.9872 - val_loss: 0.1393 - val_accuracy: 0.9902\n",
      "Test set loss: 0.22622165083885193, test set accuracy: 0.9689000248908997\n",
      "epoch 7\n",
      "3375/3375 [==============================] - 342s 101ms/step - loss: 0.1368 - accuracy: 0.9874 - val_loss: 0.1728 - val_accuracy: 0.9805\n",
      "Test set loss: 0.32994288206100464, test set accuracy: 0.9521999955177307\n",
      "epoch 8\n",
      "3375/3375 [==============================] - 341s 101ms/step - loss: 0.1313 - accuracy: 0.9890 - val_loss: 0.1326 - val_accuracy: 0.9897\n",
      "Test set loss: 0.23809121549129486, test set accuracy: 0.9697999954223633\n",
      "epoch 9\n",
      "3375/3375 [==============================] - 340s 101ms/step - loss: 0.1279 - accuracy: 0.9894 - val_loss: 0.1357 - val_accuracy: 0.9907\n",
      "Test set loss: 0.21927092969417572, test set accuracy: 0.972599983215332\n",
      "epoch 10\n",
      "3375/3375 [==============================] - 341s 101ms/step - loss: 0.1244 - accuracy: 0.9900 - val_loss: 0.1381 - val_accuracy: 0.9888\n",
      "Test set loss: 0.26404738426208496, test set accuracy: 0.9621999859809875\n"
     ]
    }
   ],
   "source": [
    "# regularizer in conv layers\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "lmbd = 0.00001\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), input_shape = (28, 28, 1), kernel_regularizer=regularizers.l2(lmbd)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), kernel_regularizer=regularizers.l2(lmbd)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(192, (3, 3), kernel_regularizer=regularizers.l2(lmbd)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), kernel_regularizer=regularizers.l2(lmbd)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), kernel_regularizer=regularizers.l2(lmbd)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "VAL_SPLIT = 0.1\n",
    "\n",
    "# opt = SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "history5 = []\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    print(\"epoch \" + str(i + 1))\n",
    "\n",
    "    history5.append( model.fit(train_X, train_y, batch_size = BATCH_SIZE, epochs = 1, validation_split = VAL_SPLIT))\n",
    "    test_out = model.evaluate(test_X, test_y, verbose = 0)\n",
    "    print(\"Test set loss: {}, test set accuracy: {}\".format(test_out[0], test_out[1]))\n",
    "\n",
    "# Accuracy on test set\n",
    "# model.evaluate(test_X, test_y, verbose = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e52631",
   "metadata": {},
   "source": [
    "l1 regularizer, lambda = 10^-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "960580e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "3375/3375 [==============================] - 341s 101ms/step - loss: 0.2745 - accuracy: 0.9328 - val_loss: 0.2200 - val_accuracy: 0.9538\n",
      "Test set loss: 0.4767687916755676, test set accuracy: 0.9018999934196472\n",
      "epoch 2\n",
      "3375/3375 [==============================] - 340s 101ms/step - loss: 0.1597 - accuracy: 0.9740 - val_loss: 0.1506 - val_accuracy: 0.9818\n",
      "Test set loss: 0.27668553590774536, test set accuracy: 0.9484000205993652\n",
      "epoch 3\n",
      "3375/3375 [==============================] - 340s 101ms/step - loss: 0.1567 - accuracy: 0.9803 - val_loss: 0.1579 - val_accuracy: 0.9852\n",
      "Test set loss: 0.31781241297721863, test set accuracy: 0.949999988079071\n",
      "epoch 4\n",
      "3375/3375 [==============================] - 340s 101ms/step - loss: 0.1602 - accuracy: 0.9832 - val_loss: 0.1587 - val_accuracy: 0.9867\n",
      "Test set loss: 0.26818883419036865, test set accuracy: 0.9605000019073486\n",
      "epoch 5\n",
      "3375/3375 [==============================] - 341s 101ms/step - loss: 0.1556 - accuracy: 0.9869 - val_loss: 0.1644 - val_accuracy: 0.9875\n",
      "Test set loss: 0.2438453584909439, test set accuracy: 0.9696000218391418\n",
      "epoch 6\n",
      "3375/3375 [==============================] - 341s 101ms/step - loss: 0.1551 - accuracy: 0.9883 - val_loss: 0.1671 - val_accuracy: 0.9852\n",
      "Test set loss: 0.27783262729644775, test set accuracy: 0.958899974822998\n",
      "epoch 7\n",
      "3375/3375 [==============================] - 341s 101ms/step - loss: 0.1468 - accuracy: 0.9906 - val_loss: 0.1838 - val_accuracy: 0.9843\n",
      "Test set loss: 0.33911800384521484, test set accuracy: 0.9587000012397766\n",
      "epoch 8\n",
      "3375/3375 [==============================] - 341s 101ms/step - loss: 0.1512 - accuracy: 0.9903 - val_loss: 0.1693 - val_accuracy: 0.9892\n",
      "Test set loss: 0.2687743306159973, test set accuracy: 0.9697999954223633\n",
      "epoch 9\n",
      "3375/3375 [==============================] - 341s 101ms/step - loss: 0.1468 - accuracy: 0.9913 - val_loss: 0.1609 - val_accuracy: 0.9897\n",
      "Test set loss: 0.297161728143692, test set accuracy: 0.9639000296592712\n",
      "epoch 10\n",
      "3375/3375 [==============================] - 341s 101ms/step - loss: 0.1435 - accuracy: 0.9921 - val_loss: 0.1857 - val_accuracy: 0.9880\n",
      "Test set loss: 0.2782774567604065, test set accuracy: 0.9678000211715698\n"
     ]
    }
   ],
   "source": [
    "# regularizer in conv layers\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "lmbd = 0.000001\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), input_shape = (28, 28, 1), kernel_regularizer=regularizers.l1(lmbd)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), kernel_regularizer=regularizers.l1(lmbd)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(192, (3, 3), kernel_regularizer=regularizers.l1(lmbd)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), kernel_regularizer=regularizers.l1(lmbd)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), kernel_regularizer=regularizers.l1(lmbd)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "VAL_SPLIT = 0.1\n",
    "\n",
    "# opt = SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "history4 = []\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    print(\"epoch \" + str(i + 1))\n",
    "\n",
    "    history4.append( model.fit(train_X, train_y, batch_size = BATCH_SIZE, epochs = 1, validation_split = VAL_SPLIT))\n",
    "    test_out = model.evaluate(test_X, test_y, verbose = 0)\n",
    "    print(\"Test set loss: {}, test set accuracy: {}\".format(test_out[0], test_out[1]))\n",
    "\n",
    "# Accuracy on test set\n",
    "# model.evaluate(test_X, test_y, verbose = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417e899f",
   "metadata": {},
   "source": [
    "mixed l1 and l2 regularizers, lambda = 10^-6 ea. (total 2 * 10^-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "960580e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "3375/3375 [==============================] - 354s 105ms/step - loss: 0.2787 - accuracy: 0.9322 - val_loss: 0.1773 - val_accuracy: 0.9678\n",
      "Test set loss: 0.40593165159225464, test set accuracy: 0.902400016784668\n",
      "epoch 2\n",
      "3375/3375 [==============================] - 354s 105ms/step - loss: 0.1701 - accuracy: 0.9727 - val_loss: 0.1702 - val_accuracy: 0.9743\n",
      "Test set loss: 0.2943055331707001, test set accuracy: 0.9366999864578247\n",
      "epoch 3\n",
      "3375/3375 [==============================] - 354s 105ms/step - loss: 0.1642 - accuracy: 0.9799 - val_loss: 0.1645 - val_accuracy: 0.9838\n",
      "Test set loss: 0.29723092913627625, test set accuracy: 0.9513000249862671\n",
      "epoch 4\n",
      "3375/3375 [==============================] - 355s 105ms/step - loss: 0.1639 - accuracy: 0.9842 - val_loss: 0.1880 - val_accuracy: 0.9780\n",
      "Test set loss: 0.2976246476173401, test set accuracy: 0.9538000226020813\n",
      "epoch 5\n",
      "3375/3375 [==============================] - 355s 105ms/step - loss: 0.1645 - accuracy: 0.9864 - val_loss: 0.1753 - val_accuracy: 0.9877\n",
      "Test set loss: 0.2731049656867981, test set accuracy: 0.9632999897003174\n",
      "epoch 6\n",
      "3375/3375 [==============================] - 355s 105ms/step - loss: 0.1645 - accuracy: 0.9873 - val_loss: 0.2092 - val_accuracy: 0.9830\n",
      "Test set loss: 0.30712708830833435, test set accuracy: 0.9606000185012817\n",
      "epoch 7\n",
      "3375/3375 [==============================] - 355s 105ms/step - loss: 0.1605 - accuracy: 0.9890 - val_loss: 0.1662 - val_accuracy: 0.9888\n",
      "Test set loss: 0.2516592741012573, test set accuracy: 0.9717000126838684\n",
      "epoch 8\n",
      "3375/3375 [==============================] - 355s 105ms/step - loss: 0.1537 - accuracy: 0.9906 - val_loss: 0.1697 - val_accuracy: 0.9890\n",
      "Test set loss: 0.26484280824661255, test set accuracy: 0.9688000082969666\n",
      "epoch 9\n",
      "3375/3375 [==============================] - 355s 105ms/step - loss: 0.1521 - accuracy: 0.9907 - val_loss: 0.1717 - val_accuracy: 0.9887\n",
      "Test set loss: 0.28141656517982483, test set accuracy: 0.9693999886512756\n",
      "epoch 10\n",
      "3375/3375 [==============================] - 355s 105ms/step - loss: 0.1482 - accuracy: 0.9916 - val_loss: 0.1804 - val_accuracy: 0.9858\n",
      "Test set loss: 0.2945660948753357, test set accuracy: 0.9672999978065491\n"
     ]
    }
   ],
   "source": [
    "# regularizer in conv layers\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "lmbd = 0.000001\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), input_shape = (28, 28, 1), kernel_regularizer=regularizers.l1_l2(lmbd, lmbd)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), kernel_regularizer=regularizers.l1_l2(lmbd, lmbd)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(192, (3, 3), kernel_regularizer=regularizers.l1_l2(lmbd, lmbd)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), kernel_regularizer=regularizers.l1_l2(lmbd, lmbd)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), kernel_regularizer=regularizers.l1_l2(lmbd, lmbd)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "VAL_SPLIT = 0.1\n",
    "\n",
    "# opt = SGD(learning_rate=0.01, momentum=0.9)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "history8 = []\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    print(\"epoch \" + str(i + 1))\n",
    "\n",
    "    history8.append( model.fit(train_X, train_y, batch_size = BATCH_SIZE, epochs = 1, validation_split = VAL_SPLIT))\n",
    "    test_out = model.evaluate(test_X, test_y, verbose = 0)\n",
    "    print(\"Test set loss: {}, test set accuracy: {}\".format(test_out[0], test_out[1]))\n",
    "\n",
    "# Accuracy on test set\n",
    "# model.evaluate(test_X, test_y, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7cd3ede2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.2787330448627472], 'accuracy': [0.9322407245635986], 'val_loss': [0.17727555334568024], 'val_accuracy': [0.9678333401679993]}\n",
      "{'loss': [0.17005014419555664], 'accuracy': [0.9727222323417664], 'val_loss': [0.17019973695278168], 'val_accuracy': [0.9743333458900452]}\n",
      "{'loss': [0.16420994699001312], 'accuracy': [0.9799259305000305], 'val_loss': [0.1644865870475769], 'val_accuracy': [0.9838333129882812]}\n",
      "{'loss': [0.16393402218818665], 'accuracy': [0.9842222332954407], 'val_loss': [0.18796473741531372], 'val_accuracy': [0.9779999852180481]}\n",
      "{'loss': [0.1645069420337677], 'accuracy': [0.9864259362220764], 'val_loss': [0.17532998323440552], 'val_accuracy': [0.987666666507721]}\n",
      "{'loss': [0.16448552906513214], 'accuracy': [0.987333357334137], 'val_loss': [0.20924004912376404], 'val_accuracy': [0.9829999804496765]}\n",
      "{'loss': [0.16049353778362274], 'accuracy': [0.9889629483222961], 'val_loss': [0.16621431708335876], 'val_accuracy': [0.9888333082199097]}\n",
      "{'loss': [0.15371578931808472], 'accuracy': [0.9906481504440308], 'val_loss': [0.16972367465496063], 'val_accuracy': [0.9890000224113464]}\n",
      "{'loss': [0.15205636620521545], 'accuracy': [0.9907037019729614], 'val_loss': [0.17170648276805878], 'val_accuracy': [0.9886666536331177]}\n",
      "{'loss': [0.1482207328081131], 'accuracy': [0.9916481375694275], 'val_loss': [0.180414080619812], 'val_accuracy': [0.9858333468437195]}\n"
     ]
    }
   ],
   "source": [
    "for i in history8:\n",
    "    print(i.history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
